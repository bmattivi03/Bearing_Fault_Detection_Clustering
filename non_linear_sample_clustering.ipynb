{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bd5de32",
   "metadata": {},
   "source": [
    "# Nonlinear Clustering Workflow — Step-by-Step Summary\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Random Sampling  \n",
    "- Loads a **random subset (7,000 rows)** from the large normalized dataset `features_ready.csv`.  \n",
    "- This prevents memory overload and speeds up computation (yes, it was the issue during tries).  \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Try: Gaussian Mixture Models (GMM)  \n",
    "- Tests several GMM configurations with **12 → 60 clusters** (step = 6).  \n",
    "- Uses `covariance_type='tied'` for stability and lower memory usage.  \n",
    "- For each model:  \n",
    "  - Fits clusters using the EM algorithm.  \n",
    "  - Calculates **Silhouette Score** and **Davies–Bouldin Index (DBI)**.  \n",
    "  - Saves results for comparison.  \n",
    "\n",
    "---\n",
    "\n",
    "## 3. Try: Spectral Clustering  \n",
    "- Runs **Spectral Clustering** with the same cluster counts (12 → 60).  \n",
    "- Uses a **nearest-neighbors affinity graph** to capture nonlinear relations.  \n",
    "- Evaluates each configuration with the same metrics (Silhouette, DBI).  \n",
    "\n",
    "---\n",
    "\n",
    "## 4. Try: DBSCAN (Density-Based)  \n",
    "- Applies **DBSCAN** with tuned parameters (`eps=0.1`, `min_samples=10`)  \n",
    "  to generate more than 10 clusters.  \n",
    "- Computes Silhouette and DBI if more than one cluster is detected.  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Evaluation of All Models \n",
    "\n",
    "### Understanding the Evaluation Formula\n",
    "\n",
    "Each clustering model is evaluated using two key metrics:\n",
    "\n",
    "1. **Silhouette Score (range: -1 → 1)**  \n",
    "   - Measures how similar each point is to its own cluster compared to other clusters.  \n",
    "   - **Interpretation:**\n",
    "     - **~1.0** → points are tightly grouped and well-separated (excellent clustering)  \n",
    "     - **~0.5** → moderately good separation  \n",
    "     - **~0.0** → overlapping clusters  \n",
    "     - **< 0** → likely incorrect clustering or too many clusters  \n",
    "\n",
    "2. **Davies–Bouldin Index (DBI, range: 0 → ∞)**  \n",
    "   - Represents the average \"similarity\" between each cluster and its most similar neighbor.  \n",
    "   - **Interpretation:**\n",
    "     - **Closer to 0** → compact, well-separated clusters (good)  \n",
    "     - **> 2.0** → poor separation or overlapping clusters  \n",
    "\n",
    "---\n",
    "\n",
    "### Combined Score Formula\n",
    "\n",
    "To compare models using both metrics, a combined score is computed:\n",
    "\n",
    "\\[\n",
    "\\text{score} = \\text{Silhouette} - 0.1 \\times \\text{DBI}\n",
    "\\]\n",
    "\n",
    "This formula balances the two metrics:\n",
    "- **Silhouette** is *maximized* (higher is better),\n",
    "- **DBI** is *penalized* (lower is better),\n",
    "- The multiplier `0.1` ensures DBI’s influence is moderate, not dominant.\n",
    "\n",
    "### How to Interpret the Combined Score (for real nonlinear data)\n",
    "\n",
    "| Combined Score | Meaning | Interpretation |\n",
    "|----------------|----------|----------------|\n",
    "| **> 0.4** | Excellent | Very distinct, compact clusters |\n",
    "| **0.2 – 0.4** | Good | Clear separation, reliable structure |\n",
    "| **-0.2 – 0.2** | Moderate | Some overlap, acceptable for complex data |\n",
    "| **-0.4 – 0.2** | Weak | Noisy or poorly separated clusters |\n",
    "| **< -0.4** | Bad | Overfitted or meaningless clustering |\n",
    "---\n",
    "\n",
    "## 6. Saving the Best Model  \n",
    "- Retrieves the cluster assignments from the best-scoring model.  \n",
    "- Adds two columns to the dataset:  \n",
    "  - `cluster` → cluster label for each sample,  \n",
    "  - `model` → model name (e.g., `Spectral_24`, `GMM_30`, `DBSCAN`).  \n",
    "- Saves the annotated results to **`clustering_results_best_nonlinear.csv`**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe36716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Load random sample to prevent the death of the laptop\n",
    "total_rows = sum(1 for _ in open(\"features_ready.csv\")) - 1\n",
    "sample_size = 7000\n",
    "skip = sorted(np.random.choice(range(1, total_rows + 1), total_rows - sample_size, replace=False))\n",
    "df = pd.read_csv(\"features_ready.csv\", skiprows=skip)\n",
    "\n",
    "#Select numeric features\n",
    "feature_cols = [c for c in df.columns if c.startswith(('t_', 'f_', 'w_'))]\n",
    "X = df[feature_cols].to_numpy(dtype=np.float64)\n",
    "results = []\n",
    "cluster_labels = {}\n",
    "\n",
    "#Gaussian Mixture\n",
    "for k in tqdm(range(12, 61, 6), desc=\"Testing GMM clusters\"):\n",
    "    try:\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=k,\n",
    "            covariance_type='tied',\n",
    "            reg_covar=1e-4,\n",
    "            max_iter=500,\n",
    "            random_state=42\n",
    "        )\n",
    "        labels_gmm = gmm.fit_predict(X)\n",
    "        sil_gmm = silhouette_score(X, labels_gmm)\n",
    "        db_gmm = davies_bouldin_score(X, labels_gmm)\n",
    "        results.append({\"model\": f\"GMM_{k}\", \"silhouette\": sil_gmm, \"db\": db_gmm, \"n_clusters\": k})\n",
    "        cluster_labels[f\"GMM_{k}\"] = labels_gmm\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ GMM (k={k}) failed: {e}\")\n",
    "\n",
    "#Spectral Clustering\n",
    "for k in tqdm(range(12, 61, 6), desc=\"Testing Spectral clusters\"):\n",
    "    try:\n",
    "        spectral = SpectralClustering(\n",
    "            n_clusters=k,\n",
    "            affinity='nearest_neighbors',\n",
    "            assign_labels='kmeans',\n",
    "            random_state=42\n",
    "        )\n",
    "        labels_sp = spectral.fit_predict(X)\n",
    "        sil_sp = silhouette_score(X, labels_sp)\n",
    "        db_sp = davies_bouldin_score(X, labels_sp)\n",
    "        results.append({\"model\": f\"Spectral_{k}\", \"silhouette\": sil_sp, \"db\": db_sp, \"n_clusters\": k})\n",
    "        cluster_labels[f\"Spectral_{k}\"] = labels_sp\n",
    "    except Exception as e:\n",
    "        print(f\"Spectral (k={k}) failed: {e}\")\n",
    "\n",
    "#DBSCAN\n",
    "try:\n",
    "    dbscan = DBSCAN(eps=0.1, min_samples=10, n_jobs=-1) #esp modified due to insufficient number of clusters before\n",
    "    labels_db = dbscan.fit_predict(X)\n",
    "    if len(set(labels_db)) > 1:\n",
    "        sil_db = silhouette_score(X, labels_db)\n",
    "        db_db = davies_bouldin_score(X, labels_db)\n",
    "        results.append({\n",
    "            \"model\": \"DBSCAN\",\n",
    "            \"silhouette\": sil_db,\n",
    "            \"db\": db_db,\n",
    "            \"n_clusters\": len(set(labels_db))\n",
    "        })\n",
    "        cluster_labels[\"DBSCAN\"] = labels_db\n",
    "except Exception as e:\n",
    "    print(f\"DBSCAN failed: {e}\")\n",
    "\n",
    "#Evaluate all nonlinear models\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results[\"score\"] = df_results[\"silhouette\"] - 0.1 * df_results[\"db\"]\n",
    "\n",
    "best_model_name = df_results.sort_values(\"score\", ascending=False).iloc[0][\"model\"]\n",
    "print(\"Model comparison (non-linear only):\")\n",
    "print(df_results.sort_values(\"score\", ascending=False).head(10))\n",
    "\n",
    "#Save best model results\n",
    "best_labels = cluster_labels[best_model_name]\n",
    "df[\"cluster\"] = best_labels\n",
    "df[\"model\"] = best_model_name\n",
    "df.to_csv(\"clustering_results_best_nonlinear.csv\", index=False)\n",
    "print(f\"\\n✅ Best nonlinear model: {best_model_name}\")\n",
    "print(\"\\nCluster size distribution:\")\n",
    "print(df[\"cluster\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00b0810",
   "metadata": {},
   "source": [
    "# Evaluation and Interpretation Guide\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dataset Overview\n",
    "The file **`clustering_results_best_nonlinear.csv`** contains:\n",
    "- Extracted time-, frequency-, and wavelet-domain features (`t_`, `f_`, `w_...`);\n",
    "- Metadata fields such as `fault_type`, `bearing_type`, and `load_level`;\n",
    "- The assigned cluster label (`cluster`);\n",
    "- The name of the nonlinear model used (`model`), e.g., `Spectral_24`, `GMM_diag_30`, or `DBSCAN`.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Cluster Evaluation Metrics\n",
    "\n",
    "| Metric | Description | Interpretation |\n",
    "|---------|--------------|----------------|\n",
    "| **Silhouette Score** | Measures cohesion and separation of clusters | Closer to **1.0** → compact, well-separated clusters |\n",
    "| **Davies–Bouldin Index (DBI)** | Ratio of within-cluster to between-cluster distances | **Lower** = better cluster quality |\n",
    "| **Cluster Count** | Number of clusters found by the algorithm | Indicates overall structure complexity |\n",
    "| **Cluster Size Distribution** | Number of samples per cluster | Detects unbalanced or noisy results |\n",
    "\n",
    "### Example: Evaluating Clusters\n",
    "Use `silhouette_score` and `davies_bouldin_score` from **scikit-learn** to quantify cluster quality.  \n",
    "The closer the silhouette score is to **1**, and the smaller the DBI, the better the clustering.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Cluster–Fault Relationship\n",
    "\n",
    "### Purpose\n",
    "To verify whether the discovered clusters correspond to known fault types or load conditions.\n",
    "\n",
    "### How to Evaluate\n",
    "- Use a **cross-tabulation** (`pd.crosstab`) between `cluster` and `fault_type` to see the proportion of each fault type in every cluster.  \n",
    "- Do the same for `load_level` or `bearing_type`.\n",
    "\n",
    "### Interpretation\n",
    "- A cluster dominated by one `fault_type` likely represents that fault condition.  \n",
    "- Mixed clusters might indicate transitional states, noise, or overlapping operating modes.  \n",
    "- If clusters group primarily by `load_level`, the model may capture load-related patterns instead of faults.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
